#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NER è¦–è¦ºåŒ–åˆ†æå·¥å…·
æ ¹æ“šä¸åŒå¯¦é«”é¡å‹ç”Ÿæˆå°æ‡‰çš„åœ–è¡¨
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import json
from collections import Counter
import numpy as np
from typing import List, Dict, Any
import warnings
warnings.filterwarnings('ignore')

# è¨­å®šä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class NERVisualizer:
    """NER è¦–è¦ºåŒ–åˆ†æå™¨"""
    
    def __init__(self):
        self.entity_colors = {
            'PERSON': '#FF6B6B',      # ç´…è‰² - äººå
            'LOCATION': '#4ECDC4',    # é’è‰² - åœ°å
            'ORGANIZATION': '#45B7D1', # è—è‰² - çµ„ç¹”
            'DATE': '#96CEB4',        # ç¶ è‰² - æ—¥æœŸ
            'MONEY': '#FFEAA7',       # é»ƒè‰² - é‡‘é¡
            'OTHER': '#DDA0DD'        # ç´«è‰² - å…¶ä»–
        }
    
    def load_data(self, csv_file: str) -> pd.DataFrame:
        """è¼‰å…¥ NER åˆ†æçµæœ"""
        try:
            df = pd.read_csv(csv_file, encoding='utf-8')
            return df
        except Exception as e:
            print(f"è¼‰å…¥è³‡æ–™éŒ¯èª¤: {e}")
            return pd.DataFrame()
    
    def parse_entities(self, df: pd.DataFrame) -> List[Dict[str, Any]]:
        """è§£æå¯¦é«”è³‡æ–™"""
        all_entities = []
        
        for _, row in df.iterrows():
            if pd.notna(row['entities']) and row['entities'] != '[]':
                try:
                    # å˜—è©¦è§£æ JSON æ ¼å¼çš„å¯¦é«”
                    if isinstance(row['entities'], str):
                        entities = json.loads(row['entities'])
                    else:
                        entities = row['entities']
                    
                    for entity in entities:
                        all_entities.append({
                            'text': entity.get('text', ''),
                            'label': entity.get('label', 'UNKNOWN'),
                            'confidence': entity.get('confidence', 0),
                            'text_id': row['text_id']
                        })
                except Exception as e:
                    print(f"è§£æå¯¦é«”éŒ¯èª¤: {e}")
                    continue
        
        return all_entities
    
    def create_entity_type_distribution(self, entities: List[Dict[str, Any]], save_path: str = None):
        """å‰µå»ºå¯¦é«”é¡å‹åˆ†å¸ƒåœ–"""
        if not entities:
            print("æ²’æœ‰å¯¦é«”è³‡æ–™å¯è¦–è¦ºåŒ–")
            return
        
        # çµ±è¨ˆå¯¦é«”é¡å‹
        entity_types = [entity['label'] for entity in entities]
        type_counts = Counter(entity_types)
        
        # å‰µå»ºåœ–è¡¨
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # åœ“é¤…åœ–
        labels = list(type_counts.keys())
        sizes = list(type_counts.values())
        colors = [self.entity_colors.get(label, self.entity_colors['OTHER']) for label in labels]
        
        ax1.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
        ax1.set_title('å¯¦é«”é¡å‹åˆ†å¸ƒ - åœ“é¤…åœ–', fontsize=14, fontweight='bold')
        
        # é•·æ¢åœ–
        bars = ax2.bar(labels, sizes, color=colors)
        ax2.set_title('å¯¦é«”é¡å‹åˆ†å¸ƒ - é•·æ¢åœ–', fontsize=14, fontweight='bold')
        ax2.set_xlabel('å¯¦é«”é¡å‹')
        ax2.set_ylabel('æ•¸é‡')
        ax2.tick_params(axis='x', rotation=45)
        
        # åœ¨é•·æ¢åœ–ä¸Šé¡¯ç¤ºæ•¸å€¼
        for bar, size in zip(bars, sizes):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                    str(size), ha='center', va='bottom')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"å¯¦é«”é¡å‹åˆ†å¸ƒåœ–å·²ä¿å­˜è‡³: {save_path}")
        
        plt.show()
    
    def create_confidence_distribution(self, entities: List[Dict[str, Any]], save_path: str = None):
        """å‰µå»ºå¯ä¿¡åº¦åˆ†å¸ƒåœ–"""
        if not entities:
            print("æ²’æœ‰å¯¦é«”è³‡æ–™å¯è¦–è¦ºåŒ–")
            return
        
        confidences = [entity['confidence'] for entity in entities]
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # ç›´æ–¹åœ–
        ax1.hist(confidences, bins=20, color='skyblue', alpha=0.7, edgecolor='black')
        ax1.set_title('å¯ä¿¡åº¦åˆ†å¸ƒ - ç›´æ–¹åœ–', fontsize=14, fontweight='bold')
        ax1.set_xlabel('å¯ä¿¡åº¦')
        ax1.set_ylabel('é »ç‡')
        ax1.axvline(np.mean(confidences), color='red', linestyle='--', 
                   label=f'å¹³å‡: {np.mean(confidences):.3f}')
        ax1.legend()
        
        # ç®±ç·šåœ–
        ax2.boxplot(confidences, patch_artist=True, 
                   boxprops=dict(facecolor='lightblue', alpha=0.7))
        ax2.set_title('å¯ä¿¡åº¦åˆ†å¸ƒ - ç®±ç·šåœ–', fontsize=14, fontweight='bold')
        ax2.set_ylabel('å¯ä¿¡åº¦')
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"å¯ä¿¡åº¦åˆ†å¸ƒåœ–å·²ä¿å­˜è‡³: {save_path}")
        
        plt.show()
    
    def create_entity_by_type_analysis(self, entities: List[Dict[str, Any]], save_path: str = None):
        """å‰µå»ºå„é¡å‹å¯¦é«”çš„è©³ç´°åˆ†æ"""
        if not entities:
            print("æ²’æœ‰å¯¦é«”è³‡æ–™å¯è¦–è¦ºåŒ–")
            return
        
        # æŒ‰é¡å‹åˆ†çµ„
        entity_groups = {}
        for entity in entities:
            label = entity['label']
            if label not in entity_groups:
                entity_groups[label] = []
            entity_groups[label].append(entity)
        
        # è¨ˆç®—æ¯å€‹é¡å‹çš„çµ±è¨ˆè³‡è¨Š
        stats = {}
        for label, group in entity_groups.items():
            confidences = [e['confidence'] for e in group]
            stats[label] = {
                'count': len(group),
                'avg_confidence': np.mean(confidences),
                'min_confidence': np.min(confidences),
                'max_confidence': np.max(confidences)
            }
        
        # å‰µå»ºåœ–è¡¨
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. å„é¡å‹å¯¦é«”æ•¸é‡
        labels = list(stats.keys())
        counts = [stats[label]['count'] for label in labels]
        colors = [self.entity_colors.get(label, self.entity_colors['OTHER']) for label in labels]
        
        bars1 = ax1.bar(labels, counts, color=colors)
        ax1.set_title('å„é¡å‹å¯¦é«”æ•¸é‡', fontsize=14, fontweight='bold')
        ax1.set_ylabel('æ•¸é‡')
        ax1.tick_params(axis='x', rotation=45)
        
        for bar, count in zip(bars1, counts):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                    str(count), ha='center', va='bottom')
        
        # 2. å„é¡å‹å¹³å‡å¯ä¿¡åº¦
        avg_confidences = [stats[label]['avg_confidence'] for label in labels]
        bars2 = ax2.bar(labels, avg_confidences, color=colors)
        ax2.set_title('å„é¡å‹å¹³å‡å¯ä¿¡åº¦', fontsize=14, fontweight='bold')
        ax2.set_ylabel('å¹³å‡å¯ä¿¡åº¦')
        ax2.tick_params(axis='x', rotation=45)
        ax2.set_ylim(0, 1)
        
        for bar, conf in zip(bars2, avg_confidences):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{conf:.3f}', ha='center', va='bottom')
        
        # 3. å„é¡å‹å¯ä¿¡åº¦åˆ†å¸ƒï¼ˆç®±ç·šåœ–ï¼‰
        confidence_data = []
        confidence_labels = []
        for label, group in entity_groups.items():
            confidences = [e['confidence'] for e in group]
            confidence_data.append(confidences)
            confidence_labels.append(label)
        
        box_plot = ax3.boxplot(confidence_data, labels=confidence_labels, patch_artist=True)
        for patch, label in zip(box_plot['boxes'], confidence_labels):
            patch.set_facecolor(self.entity_colors.get(label, self.entity_colors['OTHER']))
            patch.set_alpha(0.7)
        
        ax3.set_title('å„é¡å‹å¯ä¿¡åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax3.set_ylabel('å¯ä¿¡åº¦')
        ax3.tick_params(axis='x', rotation=45)
        ax3.grid(True, alpha=0.3)
        
        # 4. å„é¡å‹å¯¦é«”è©³ç´°çµ±è¨ˆè¡¨
        ax4.axis('tight')
        ax4.axis('off')
        
        table_data = []
        for label in labels:
            table_data.append([
                label,
                stats[label]['count'],
                f"{stats[label]['avg_confidence']:.3f}",
                f"{stats[label]['min_confidence']:.3f}",
                f"{stats[label]['max_confidence']:.3f}"
            ])
        
        table = ax4.table(cellText=table_data,
                         colLabels=['é¡å‹', 'æ•¸é‡', 'å¹³å‡å¯ä¿¡åº¦', 'æœ€ä½å¯ä¿¡åº¦', 'æœ€é«˜å¯ä¿¡åº¦'],
                         cellLoc='center',
                         loc='center')
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1.2, 1.5)
        
        # è¨­å®šè¡¨æ ¼é¡è‰²
        for i, label in enumerate(labels):
            color = self.entity_colors.get(label, self.entity_colors['OTHER'])
            for j in range(len(table_data[0])):
                table[(i+1, j)].set_facecolor(color)
                table[(i+1, j)].set_alpha(0.3)
        
        ax4.set_title('è©³ç´°çµ±è¨ˆè¡¨', fontsize=14, fontweight='bold', pad=20)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"å„é¡å‹å¯¦é«”åˆ†æåœ–å·²ä¿å­˜è‡³: {save_path}")
        
        plt.show()
    
    def create_top_entities(self, entities: List[Dict[str, Any]], top_n: int = 10, save_path: str = None):
        """å‰µå»ºæœ€å¸¸è¦‹å¯¦é«”æ’è¡Œæ¦œ"""
        if not entities:
            print("æ²’æœ‰å¯¦é«”è³‡æ–™å¯è¦–è¦ºåŒ–")
            return
        
        # çµ±è¨ˆæœ€å¸¸è¦‹çš„å¯¦é«”
        entity_texts = [entity['text'] for entity in entities]
        text_counts = Counter(entity_texts)
        top_entities = text_counts.most_common(top_n)
        
        if not top_entities:
            print("æ²’æœ‰æ‰¾åˆ°å¯¦é«”")
            return
        
        # å‰µå»ºåœ–è¡¨
        fig, ax = plt.subplots(figsize=(12, 8))
        
        texts = [item[0] for item in top_entities]
        counts = [item[1] for item in top_entities]
        
        # æ ¹æ“šå¯¦é«”é¡å‹è¨­å®šé¡è‰²
        colors = []
        for text in texts:
            # æ‰¾åˆ°å°æ‡‰çš„å¯¦é«”é¡å‹
            entity_type = None
            for entity in entities:
                if entity['text'] == text:
                    entity_type = entity['label']
                    break
            color = self.entity_colors.get(entity_type, self.entity_colors['OTHER'])
            colors.append(color)
        
        bars = ax.barh(texts, counts, color=colors, alpha=0.7)
        ax.set_title(f'æœ€å¸¸è¦‹å¯¦é«”æ’è¡Œæ¦œ (å‰ {top_n} å)', fontsize=14, fontweight='bold')
        ax.set_xlabel('å‡ºç¾æ¬¡æ•¸')
        
        # åœ¨é•·æ¢ä¸Šé¡¯ç¤ºæ•¸å€¼
        for bar, count in zip(bars, counts):
            ax.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2,
                   str(count), ha='left', va='center')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"æœ€å¸¸è¦‹å¯¦é«”æ’è¡Œæ¦œå·²ä¿å­˜è‡³: {save_path}")
        
        plt.show()
    
    def create_comprehensive_analysis(self, csv_file: str, output_dir: str = "ner_analysis"):
        """å‰µå»ºå®Œæ•´çš„è¦–è¦ºåŒ–åˆ†æ"""
        import os
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        os.makedirs(output_dir, exist_ok=True)
        
        print("ğŸ” è¼‰å…¥è³‡æ–™...")
        df = self.load_data(csv_file)
        if df.empty:
            print("âŒ ç„¡æ³•è¼‰å…¥è³‡æ–™")
            return
        
        print("ğŸ“Š è§£æå¯¦é«”...")
        entities = self.parse_entities(df)
        if not entities:
            print("âŒ æ²’æœ‰æ‰¾åˆ°å¯¦é«”è³‡æ–™")
            return
        
        print(f"âœ… æ‰¾åˆ° {len(entities)} å€‹å¯¦é«”")
        
        # ç”Ÿæˆå„ç¨®åœ–è¡¨
        print("\nğŸ“ˆ ç”Ÿæˆå¯¦é«”é¡å‹åˆ†å¸ƒåœ–...")
        self.create_entity_type_distribution(entities, f"{output_dir}/entity_type_distribution.png")
        
        print("ğŸ“Š ç”Ÿæˆå¯ä¿¡åº¦åˆ†å¸ƒåœ–...")
        self.create_confidence_distribution(entities, f"{output_dir}/confidence_distribution.png")
        
        print("ğŸ” ç”Ÿæˆå„é¡å‹è©³ç´°åˆ†æ...")
        self.create_entity_by_type_analysis(entities, f"{output_dir}/entity_by_type_analysis.png")
        
        print("ğŸ† ç”Ÿæˆæœ€å¸¸è¦‹å¯¦é«”æ’è¡Œæ¦œ...")
        self.create_top_entities(entities, top_n=15, save_path=f"{output_dir}/top_entities.png")
        
        # ç”Ÿæˆçµ±è¨ˆå ±å‘Š
        self.generate_statistics_report(entities, f"{output_dir}/statistics_report.txt")
        
        print(f"\nğŸ‰ æ‰€æœ‰åˆ†æåœ–è¡¨å·²ä¿å­˜è‡³ '{output_dir}' ç›®éŒ„")
    
    def generate_statistics_report(self, entities: List[Dict[str, Any]], save_path: str):
        """ç”Ÿæˆçµ±è¨ˆå ±å‘Š"""
        if not entities:
            return
        
        # çµ±è¨ˆåˆ†æ
        entity_types = [entity['label'] for entity in entities]
        type_counts = Counter(entity_types)
        confidences = [entity['confidence'] for entity in entities]
        
        # æŒ‰é¡å‹åˆ†çµ„çµ±è¨ˆ
        type_stats = {}
        for label in type_counts.keys():
            type_entities = [e for e in entities if e['label'] == label]
            type_confidences = [e['confidence'] for e in type_entities]
            type_stats[label] = {
                'count': len(type_entities),
                'avg_confidence': np.mean(type_confidences),
                'min_confidence': np.min(type_confidences),
                'max_confidence': np.max(type_confidences)
            }
        
        # ç”Ÿæˆå ±å‘Š
        report = f"""
NER åˆ†æçµ±è¨ˆå ±å‘Š
================

ç¸½é«”çµ±è¨ˆ
--------
ç¸½å¯¦é«”æ•¸: {len(entities)}
å¹³å‡å¯ä¿¡åº¦: {np.mean(confidences):.3f}
æœ€é«˜å¯ä¿¡åº¦: {np.max(confidences):.3f}
æœ€ä½å¯ä¿¡åº¦: {np.min(confidences):.3f}

å„é¡å‹çµ±è¨ˆ
----------
"""
        
        for label, stats in type_stats.items():
            report += f"""
{label}:
  æ•¸é‡: {stats['count']}
  å¹³å‡å¯ä¿¡åº¦: {stats['avg_confidence']:.3f}
  æœ€é«˜å¯ä¿¡åº¦: {stats['max_confidence']:.3f}
  æœ€ä½å¯ä¿¡åº¦: {stats['min_confidence']:.3f}
"""
        
        # æœ€å¸¸è¦‹å¯¦é«”
        entity_texts = [entity['text'] for entity in entities]
        text_counts = Counter(entity_texts)
        top_entities = text_counts.most_common(10)
        
        report += f"""

æœ€å¸¸è¦‹å¯¦é«” (å‰10å)
------------------
"""
        for i, (text, count) in enumerate(top_entities, 1):
            report += f"{i:2d}. {text} (å‡ºç¾ {count} æ¬¡)\n"
        
        # ä¿å­˜å ±å‘Š
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"çµ±è¨ˆå ±å‘Šå·²ä¿å­˜è‡³: {save_path}")

def main():
    """ä¸»ç¨‹å¼"""
    print("ğŸš€ NER è¦–è¦ºåŒ–åˆ†æå·¥å…·")
    print("=" * 50)
    
    visualizer = NERVisualizer()
    
    # æª¢æŸ¥æ˜¯å¦æœ‰ CSV æª”æ¡ˆ
    csv_file = 'ner_labeled_data.csv'
    if not pd.io.common.file_exists(csv_file):
        print(f"âŒ æ‰¾ä¸åˆ° {csv_file} æª”æ¡ˆ")
        print("è«‹å…ˆåŸ·è¡Œ NER åˆ†æç¨‹å¼ç”Ÿæˆè³‡æ–™")
        return
    
    # åŸ·è¡Œå®Œæ•´åˆ†æ
    visualizer.create_comprehensive_analysis(csv_file)

if __name__ == "__main__":
    main()
